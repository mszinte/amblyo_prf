{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cca4ff21-660f-478e-800e-0245edb403cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Computation of magnification factor using pycortex\n",
    "__To do :__\n",
    "- [x] adapt it to vertice analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "231df2ed-083b-49eb-964c-8c42757af0d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stop warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# General imports\n",
    "import cortex\n",
    "import importlib\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"{}/../../../utils\".format(os.getcwd()))\n",
    "from pycortex_utils import draw_cortex, set_pycortex_config_file, load_surface_pycortex\n",
    "import nibabel as nb\n",
    "\n",
    "# Define analysis parameters\n",
    "with open('../../../settings.json') as f:\n",
    "    json_s = f.read()\n",
    "    analysis_info = json.loads(json_s)\n",
    "tasks = analysis_info[\"task_names\"]\n",
    "task = tasks[0]\n",
    "rois = analysis_info[\"rois\"]\n",
    "vert_dist_th = analysis_info['vertex_pcm_rad']\n",
    "formats = analysis_info['formats']\n",
    "\n",
    "# debug\n",
    "formats = ['fsnative']\n",
    "rois = ['V1']\n",
    "\n",
    "# Inputs\n",
    "main_dir = '/home/mszinte/disks/meso_S/data'\n",
    "project_dir = 'amblyo_prf'\n",
    "subject = 'sub-01'\n",
    "deriv_fn_label = 'avg-gridfit'\n",
    "model = 'gauss'\n",
    "\n",
    "# Set pycortex db and colormaps\n",
    "cortex_dir = \"{}/{}/derivatives/pp_data/cortex\".format(main_dir, project_dir)\n",
    "set_pycortex_config_file(cortex_dir)\n",
    "importlib.reload(cortex)\n",
    "\n",
    "\n",
    "for format_, pycortex_subject in zip(formats, [subject, 'sub-170k']):\n",
    "    \n",
    "    # define directories and fn\n",
    "    prf_dir = \"{}/{}/derivatives/pp_data/{}/{}/prf\".format(main_dir, project_dir, \n",
    "                                                           subject, format_)\n",
    "    fit_dir = \"{}/fit\".format(prf_dir)\n",
    "    prf_deriv_dir = \"{}/prf_derivatives\".format(prf_dir)\n",
    "\n",
    "    if format_ == 'fsnative':\n",
    "        deriv_avg_fn_L = '{}/{}_task-{}_hemi-L_fmriprep_dct_avg_prf-deriv_{}_gridfit.func.gii'.format(\n",
    "            prf_deriv_dir, subject, task, model)\n",
    "        deriv_avg_fn_R = '{}/{}_task-{}_hemi-R_fmriprep_dct_avg_prf-deriv_{}_gridfit.func.gii'.format(\n",
    "            prf_deriv_dir, subject, task, model)\n",
    "        deriv_mat = load_surface_pycortex(L_fn=deriv_avg_fn_L, \n",
    "                                          R_fn=deriv_avg_fn_R,)\n",
    "        \n",
    "    elif format_ == '170k':\n",
    "        deriv_avg_fn = '{}/{}_task-{}_fmriprep_dct_avg_prf-deriv_{}_gridfit.dtseries.nii'.format(\n",
    "            prf_deriv_dir, subject, task, model)\n",
    "        deriv_mat = load_surface_pycortex(brain_fn=deriv_avg_fn)\n",
    "        save_svg = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04a33902-2890-4eae-bf2d-681fdb363043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get surfaces for each hemisphere\n",
    "surfs = [cortex.polyutils.Surface(*d) for d in cortex.db.get_surf(subject, \"flat\")]\n",
    "surf_lh, surf_rh = surfs[0], surfs[1]\n",
    "# get the vertices number per hemisphere\n",
    "lh_vert_num, rh_vert_num = surf_lh.pts.shape[0], surf_rh.pts.shape[0]\n",
    "vert_num = lh_vert_num + rh_vert_num\n",
    "\n",
    "# get a dicst with the surface vertices contained in each ROI\n",
    "roi_verts_dict = cortex.utils.get_roi_verts(subject, mask=False)\n",
    "#### TO REPLACE BY YOUR NEW FUNCTION TO GET ROIS FROM NPZ IN CASE OF SUB-17K\n",
    "\n",
    "# derivatives settings\n",
    "rsq_idx, ecc_idx, polar_real_idx, polar_imag_idx , size_idx, \\\n",
    "    amp_idx, baseline_idx, x_idx, y_idx, hrf_1_idx, hrf_2_idx = \\\n",
    "    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n",
    "if model == 'gauss':\n",
    "    loo_rsq_idx = 11\n",
    "elif model == 'dn':\n",
    "    srf_amp_idx = 11\n",
    "    sff_size = 12\n",
    "    neural_baseline_idx = 13\n",
    "    surround_baseline = 14\n",
    "    loo_rsq_idx = 15\n",
    "elif model == 'css':\n",
    "    n_idx = 11\n",
    "    loo_rsq_idx = 12\n",
    "\n",
    "# parameters\n",
    "vert_rsq_data = deriv_mat[rsq_idx, ...]\n",
    "vert_x_data = deriv_mat[x_idx, ...]\n",
    "vert_y_data = deriv_mat[y_idx, ...]\n",
    "vert_size_data = deriv_mat[size_idx, ...]\n",
    "vert_ecc_data = deriv_mat[ecc_idx, ...]\n",
    "\n",
    "# create empty results\n",
    "vert_cm = np.zeros(vert_num)*np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6965aae4-70e7-413c-a602-e12467f6ef45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 7, 8]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[rsq_idx, ecc_idx, size_idx, x_idx, y_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d5199f3-3493-4aea-a3c1-8ea50f1d6307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI -> V1 / Hemisphere -> lh\n",
      "ROI -> V1 / Hemisphere -> rh\n"
     ]
    }
   ],
   "source": [
    "for roi in rois:\n",
    "    # find ROI vertex\n",
    "    roi_vert_lh_idx = roi_verts_dict[roi][roi_verts_dict[roi]<lh_vert_num]\n",
    "    roi_vert_rh_idx = roi_verts_dict[roi][roi_verts_dict[roi]>=lh_vert_num]\n",
    "    roi_surf_lh_idx = roi_vert_lh_idx\n",
    "    roi_surf_rh_idx = roi_vert_rh_idx-lh_vert_num\n",
    "\n",
    "    # get mean distance of surounding vertices included in threshold\n",
    "    vert_lh_rsq, vert_lh_size = vert_rsq_data[:lh_vert_num], vert_size_data[:lh_vert_num]\n",
    "    vert_lh_x, vert_lh_y = vert_x_data[:lh_vert_num], vert_y_data[:lh_vert_num]\n",
    "    vert_rh_rsq, vert_rh_size = vert_rsq_data[lh_vert_num:], vert_size_data[lh_vert_num:]\n",
    "    vert_rh_x, vert_rh_y = vert_x_data[lh_vert_num:], vert_y_data[lh_vert_num:]\n",
    "\n",
    "    for hemi in ['lh','rh']:\n",
    "        if hemi == 'lh':\n",
    "            surf = surf_lh\n",
    "            roi_vert_idx, roi_surf_idx = roi_vert_lh_idx, roi_surf_lh_idx\n",
    "            vert_rsq, vert_x, vert_y, vert_size = vert_lh_rsq, vert_lh_x, vert_lh_y, vert_lh_size\n",
    "        elif hemi == 'rh':\n",
    "            surf = surf_rh\n",
    "            roi_vert_idx, roi_surf_idx = roi_vert_rh_idx, roi_surf_rh_idx\n",
    "            vert_rsq, vert_x, vert_y, vert_size = vert_rh_rsq, vert_rh_x, vert_rh_y, vert_rh_size\n",
    "\n",
    "        desc = 'ROI -> {} / Hemisphere -> {}'.format(roi, hemi)\n",
    "        print(desc)\n",
    "        for i, (vert_idx, surf_idx) in enumerate(zip(roi_vert_idx, roi_surf_idx)):\n",
    "\n",
    "            if vert_rsq[surf_idx] > 0:\n",
    "\n",
    "                # get geodesic distances (mm)\n",
    "                try :\n",
    "                    geo_patch = surf.get_geodesic_patch(radius=vert_dist_th, vertex=surf_idx)\n",
    "                except Exception as e:\n",
    "                    print(\"Vertex #{}: error: {} within {} mm\".format(vert_idx, e, vert_dist_th))\n",
    "                    geo_patch['vertex_mask'] = np.zeros(surf.pts.shape[0]).astype(bool)\n",
    "                    geo_patch['geodesic_distance'] = []\n",
    "\n",
    "                vert_dist_th_idx  = geo_patch['vertex_mask']\n",
    "                vert_dist_th_dist = np.ones_like(vert_dist_th_idx)*np.nan\n",
    "                vert_dist_th_dist[vert_dist_th_idx] = geo_patch['geodesic_distance']\n",
    "\n",
    "                # exclude vextex out of roi\n",
    "                vert_dist_th_not_in_roi_idx = [idx for idx in np.where(vert_dist_th_idx)[0] if idx not in roi_surf_idx]\n",
    "                vert_dist_th_idx[vert_dist_th_not_in_roi_idx] = False\n",
    "                vert_dist_th_dist[vert_dist_th_not_in_roi_idx] = np.nan\n",
    "\n",
    "                if np.sum(vert_dist_th_idx) > 0:\n",
    "\n",
    "                    # compute average geodesic distance excluding distance to itself (see [1:])\n",
    "                    vert_geo_dist_avg = np.nanmean(vert_dist_th_dist[1:])\n",
    "\n",
    "                    # get prf parameters of vertices in geodesic distance threshold\n",
    "                    vert_ctr_x, vert_ctr_y = vert_x[surf_idx], vert_y[surf_idx]\n",
    "                    vert_dist_th_idx[surf_idx] = False\n",
    "                    vert_srd_x, vert_srd_y = np.nanmean(vert_x[vert_dist_th_idx]), np.nanmean(vert_y[vert_dist_th_idx])\n",
    "\n",
    "                    # compute prf center suround distance (deg)\n",
    "                    vert_prf_dist = np.sqrt((vert_ctr_x - vert_srd_x)**2 + (vert_ctr_y - vert_srd_y)**2)\n",
    "\n",
    "                    # compute cortical magnification in mm/deg (surface distance / pRF positon distance)\n",
    "                    vert_cm[vert_idx] = vert_geo_dist_avg/vert_prf_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ee75d36-1167-4ffb-bdfb-5fcc7456e97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "deriv_mat_new = np.zeros((deriv_mat.shape[0]+1, deriv_mat.shape[1]))*np.nan\n",
    "deriv_mat_new[0:-1,...] = deriv_mat\n",
    "deriv_mat_new[-1,...] = vert_cm\n",
    "### TO SAVE WITH NEW save_surface_pycortex WHICH WILL SPLIT DATA FOR GIFTI BUT NOT CIFTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec24d28a-ee95-4c15-95b7-4a538a76859d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mszinte",
   "language": "python",
   "name": "mszinte"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
